{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# INIZIALIZZAZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T23:31:02.723174500Z",
     "start_time": "2023-12-22T23:27:36.631310200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Collecting git+https://github.com/openai/CLIP.git\r\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-wf0dpfnc\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-wf0dpfnc\r\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting ftfy\r\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.4/53.4 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: regex in /usr/local/anaconda3/lib/python3.9/site-packages (2022.7.9)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/anaconda3/lib/python3.9/site-packages (4.64.1)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/anaconda3/lib/python3.9/site-packages (1.0.2)\r\n",
      "Collecting datasets\r\n",
      "  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m507.1/507.1 kB\u001B[0m \u001B[31m15.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting wcwidth<0.3.0,>=0.2.12\r\n",
      "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\r\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.21.5)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.9.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\r\n",
      "Collecting xxhash\r\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m193.8/193.8 kB\u001B[0m \u001B[31m28.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (3.6.0)\r\n",
      "Collecting aiohttp\r\n",
      "  Downloading aiohttp-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m49.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.4)\r\n",
      "Collecting pyarrow>=8.0.0\r\n",
      "  Downloading pyarrow-14.0.2-cp39-cp39-manylinux_2_28_x86_64.whl (38.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m38.0/38.0 MB\u001B[0m \u001B[31m32.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting multiprocess\r\n",
      "  Downloading multiprocess-0.70.15-py39-none-any.whl (133 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m133.3/133.3 kB\u001B[0m \u001B[31m17.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting pyarrow-hotfix\r\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (2.28.1)\r\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0\r\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m166.4/166.4 kB\u001B[0m \u001B[31m21.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\r\n",
      "Collecting huggingface-hub>=0.19.4\r\n",
      "  Downloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m330.1/330.1 kB\u001B[0m \u001B[31m29.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.4)\r\n",
      "Collecting torch\r\n",
      "  Downloading torch-2.1.2-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m670.2/670.2 MB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting torchvision\r\n",
      "  Downloading torchvision-0.16.2-cp39-cp39-manylinux1_x86_64.whl (6.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.8/6.8 MB\u001B[0m \u001B[31m58.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting yarl<2.0,>=1.0\r\n",
      "  Downloading yarl-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m304.3/304.3 kB\u001B[0m \u001B[31m32.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting multidict<7.0,>=4.5\r\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m114.2/114.2 kB\u001B[0m \u001B[31m12.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting frozenlist>=1.1.1\r\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m240.7/240.7 kB\u001B[0m \u001B[31m29.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting async-timeout<5.0,>=4.0\r\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\r\n",
      "Collecting aiosignal>=1.1.2\r\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.19.4->datasets) (4.3.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.11)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.9.14)\r\n",
      "Collecting dill<0.3.8,>=0.3.0\r\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m115.3/115.3 kB\u001B[0m \u001B[31m16.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m53.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 MB\u001B[0m \u001B[31m14.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nccl-cu12==2.18.1\r\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m209.8/209.8 MB\u001B[0m \u001B[31m9.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cublas-cu12==12.1.3.1\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting triton==2.1.0\r\n",
      "  Downloading triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m89.3/89.3 MB\u001B[0m \u001B[31m18.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /usr/local/anaconda3/lib/python3.9/site-packages (from torch->clip==1.0) (2.11.3)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.5/56.5 MB\u001B[0m \u001B[31m26.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.6/823.6 kB\u001B[0m \u001B[31m44.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cufft-cu12==11.0.2.54\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.6/121.6 MB\u001B[0m \u001B[31m14.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.0/196.0 MB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m43.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: sympy in /usr/local/anaconda3/lib/python3.9/site-packages (from torch->clip==1.0) (1.10.1)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m12.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: networkx in /usr/local/anaconda3/lib/python3.9/site-packages (from torch->clip==1.0) (2.8.4)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m731.7/731.7 MB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nvjitlink-cu12\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.5/20.5 MB\u001B[0m \u001B[31m44.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from torchvision->clip==1.0) (9.2.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/anaconda3/lib/python3.9/site-packages (from jinja2->torch->clip==1.0) (2.0.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/anaconda3/lib/python3.9/site-packages (from sympy->torch->clip==1.0) (1.2.1)\r\n",
      "Building wheels for collected packages: clip\r\n",
      "  Building wheel for clip (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369500 sha256=73a10ef74d624b57e32e4290cb2c7727c761d3bb90376c9032666e18ba99574b\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mwglz_1f/wheels/c8/e4/e1/11374c111387672fc2068dfbe0d4b424cb9cdd1b2e184a71b5\r\n",
      "Successfully built clip\r\n",
      "Installing collected packages: wcwidth, xxhash, triton, pyarrow-hotfix, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multidict, ftfy, fsspec, frozenlist, dill, async-timeout, yarl, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, aiosignal, nvidia-cusolver-cu12, aiohttp, torch, torchvision, datasets, clip\r\n",
      "\u001B[33m  WARNING: The script ftfy is installed in '/homes/aonori/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  WARNING: The script huggingface-cli is installed in '/homes/aonori/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/homes/aonori/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33m  WARNING: The script datasets-cli is installed in '/homes/aonori/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\u001B[33m\r\n",
      "\u001B[0mSuccessfully installed aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 clip-1.0 datasets-2.16.0 dill-0.3.7 frozenlist-1.4.1 fsspec-2023.10.0 ftfy-6.1.3 huggingface-hub-0.20.1 multidict-6.0.4 multiprocess-0.70.15 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 pyarrow-14.0.2 pyarrow-hotfix-0.6 torch-2.1.2 torchvision-0.16.2 triton-2.1.0 wcwidth-0.2.12 xxhash-3.4.1 yarl-1.9.4\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: datasets in /homes/aonori/.local/lib/python3.9/site-packages (2.16.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (4.64.1)\r\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /homes/aonori/.local/lib/python3.9/site-packages (from datasets) (2023.10.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (2.28.1)\r\n",
      "Requirement already satisfied: xxhash in /homes/aonori/.local/lib/python3.9/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /homes/aonori/.local/lib/python3.9/site-packages (from datasets) (0.70.15)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /homes/aonori/.local/lib/python3.9/site-packages (from datasets) (0.3.7)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /homes/aonori/.local/lib/python3.9/site-packages (from datasets) (0.20.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\r\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.4)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /homes/aonori/.local/lib/python3.9/site-packages (from datasets) (14.0.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (3.6.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/anaconda3/lib/python3.9/site-packages (from datasets) (1.21.5)\r\n",
      "Requirement already satisfied: aiohttp in /homes/aonori/.local/lib/python3.9/site-packages (from datasets) (3.9.1)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /homes/aonori/.local/lib/python3.9/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /homes/aonori/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /homes/aonori/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /homes/aonori/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /homes/aonori/.local/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /homes/aonori/.local/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.19.4->datasets) (4.3.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.11)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.9.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install ftfy regex tqdm scikit-learn datasets git+https://github.com/openai/CLIP.git\n",
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import clip\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairface = datasets.load_dataset('HuggingFaceM4/FairFace')['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset infos\n",
    "print(fairface.shape)\n",
    "print(fairface.features.keys())\n",
    "print(fairface.features['age'].names)\n",
    "print(fairface.features['gender'].names)\n",
    "print(fairface.features['race'].names)\n",
    "print(fairface.features['service_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = {'Doctor': 'A photo of a doctor',\n",
    "#           'Nurse': 'A photo of a nurse',\n",
    "#           'Engineer': 'A photo of a engineer',\n",
    "#           'Teacher': 'A photo of a teacher',\n",
    "#           'Software Developer': 'A photo of a software developer',\n",
    "#           'CEO': 'A photo of a CEO',}\n",
    "\n",
    "labels = {'Competent': 'A photo of a competent person',\n",
    "          'Intelligent': 'A photo of an intelligent person',\n",
    "          'Skillful': 'A photo of a skillful person',\n",
    "          'Honest': 'A photo of an honest person',\n",
    "          'Trustworthy ': 'A photo of a trustworthy person',\n",
    "          'Empathetic': 'A photo of an empathetic person',\n",
    "          'Motivated': 'A photo of a motivated person',\n",
    "          'Patient': 'A photo of a patient person',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = list(labels.keys())\n",
    "prompts = list(labels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face:\n",
    "  def __init__(self, fairface_face):\n",
    "    self.race = fairface.features['race'].int2str(fairface_face['race'])\n",
    "    self.gender = fairface.features['gender'].int2str(fairface_face['gender'])\n",
    "    self.label = f'{self.race}_{self.gender}'\n",
    "    # for the experiments we combine the FairFace race and gender labels\n",
    "\n",
    "    with torch.no_grad():\n",
    "      image_input = preprocess(fairface_face['image']).unsqueeze(0).to(device)\n",
    "      self.image_features = model.encode_image(image_input)\n",
    "      self.image_features /= self.image_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(faces):\n",
    "  labels, predictions = [], []\n",
    "\n",
    "  for face in tqdm(faces):\n",
    "    # distribuzione di probabilità che misura la similarità tra le caratteristiche dell'immagine e i prompt di testo\n",
    "    similarity = (100.0 * face.image_features @ prompt_features.T).softmax(dim=-1)\n",
    "\n",
    "    # restituirà il valore massimo (value) e l'indice corrispondente (index)\n",
    "    [value], [index] = similarity[0].topk(1)\n",
    "\n",
    "    #  conterrà l'etichetta di classe prevista per l'immagine in base al confronto con i prompt di testo\n",
    "    prediction = class_labels[index]\n",
    "\n",
    "    labels.append(face.label)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "  return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = ['ViT-B/16']\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model, preprocess = clip.load(name=MODELS[0], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip.tokenize : Returns a LongTensor containing tokenized sequences of given text input\n",
    "tokenized_prompts = torch.cat([clip.tokenize(prompt) for prompt in prompts]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  # prende i prompt di testo tokenizzati e li converte in rappresentazioni numeriche (embedding)\n",
    "  prompt_features = model.encode_text(tokenized_prompts)\n",
    "  prompt_features /= prompt_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "  faces = [Face(face) for face in tqdm(fairface)]\n",
    "  fairface_labels, predictions = classify(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Heatmap(fairface_labels, predictions):\n",
    "  pairs = list(zip(fairface_labels, predictions))\n",
    "  counts = Counter(pairs)\n",
    "\n",
    "  unique_labels = sorted(set(fairface_labels))\n",
    "  unique_predictions = sorted(set(predictions))\n",
    "  matrix = np.zeros((len(unique_labels), len(unique_predictions)))\n",
    "\n",
    "  for i, label in enumerate(unique_labels):\n",
    "      for j, pred in enumerate(unique_predictions):\n",
    "          matrix[i, j] = counts.get((label, pred), 0)\n",
    "\n",
    "  row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "  percentage_matrix = (matrix / row_sums) * 100\n",
    "\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  sns.set(font_scale=0.7)\n",
    "  ax = sns.heatmap(percentage_matrix, annot=True, fmt='.2f', cmap='Greens',\n",
    "                  xticklabels=unique_predictions,\n",
    "                  yticklabels=unique_labels,\n",
    "                  annot_kws={\"size\": 8})\n",
    "  plt.xlabel('Predicted')\n",
    "  plt.ylabel('True')\n",
    "  plt.title('Prediction Distribution Percentage')\n",
    "  plt.show()\n",
    "\n",
    "  return percentage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_matrix = create_Heatmap(fairface_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAFICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_race = ['Black', 'East Asian', 'Indian', 'Latino_Hispanic', 'Middle Eastern', 'Southeast Asian', 'White']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_list = []\n",
    "\n",
    "for i, label in enumerate(sorted(set(fairface_labels))):\n",
    "  doctor_list.append(percentage_matrix[i][1])\n",
    "\n",
    "paired_data = np.array(doctor_list).reshape(-1, 2)\n",
    "normalized_data = paired_data / paired_data.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(labels_race))\n",
    "\n",
    "for i in range(normalized_data.shape[1]):\n",
    "    bars = ax.bar(index + i * bar_width, normalized_data[:, i], bar_width, label=['Female', 'Male'][i], color=['lightcoral', '#1f78b4'][i])\n",
    "\n",
    "ax.set_xlabel('Doctor')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Distribution Percentage for Doctor Class')\n",
    "\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(labels_race, rotation=45, ha='right')  \n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softwaredev_list = []\n",
    "\n",
    "for i, label in enumerate(sorted(set(fairface_labels))):\n",
    "  softwaredev_list.append(percentage_matrix[i][4])\n",
    "\n",
    "paired_data = np.array(softwaredev_list).reshape(-1, 2)\n",
    "normalized_data = paired_data / paired_data.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(labels_race))\n",
    "\n",
    "for i in range(normalized_data.shape[1]):\n",
    "    bars = ax.bar(index + i * bar_width, normalized_data[:, i], bar_width, label=['Female', 'Male'][i], color=['lightcoral', '#1f78b4'][i])\n",
    "\n",
    "ax.set_xlabel('Software Developer')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Distribution Percentage for Software Developer Class')\n",
    "\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(labels_race, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teachers_list = []\n",
    "\n",
    "for i, label in enumerate(sorted(set(fairface_labels))):\n",
    "  teachers_list.append(percentage_matrix[i][5])\n",
    "\n",
    "paired_data = np.array(teachers_list).reshape(-1, 2)\n",
    "normalized_data = paired_data / paired_data.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(labels_race))\n",
    "\n",
    "for i in range(normalized_data.shape[1]):\n",
    "    bars = ax.bar(index + i * bar_width, normalized_data[:, i], bar_width, label=['Female', 'Male'][i], color=['lightcoral', '#1f78b4'][i])\n",
    "\n",
    "ax.set_xlabel('Teacher')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Distribution Percentage for Teachers Class')\n",
    "\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(labels_race, rotation=45, ha='right') \n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"doctors.jpg\"\n",
    "image_input = Image.open(image_path)\n",
    "image_input = preprocess(image_input).unsqueeze(0).to(device)\n",
    "image_features = model.encode_image(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = (100.0 * image_features @ prompt_features.T).softmax(dim=-1)\n",
    "\n",
    "[value], [index] = similarity[0].topk(1)\n",
    "prediction = class_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from segment_anything import build_sam, SamAutomaticMaskGenerator\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"vit_h\"\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint='/content/drive/MyDrive/Tirocinio/model.pth').to(device=device)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)\n",
    "\n",
    "def convert_box_xywh_to_xyxy(box):\n",
    "    x1 = box[0]\n",
    "    y1 = box[1]\n",
    "    x2 = box[0] + box[2]\n",
    "    y2 = box[1] + box[3]\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def segment_image(image, segmentation_mask):\n",
    "    image_array = np.array(image)\n",
    "    segmented_image_array = np.zeros_like(image_array)\n",
    "    segmented_image_array[segmentation_mask] = image_array[segmentation_mask]\n",
    "    segmented_image = Image.fromarray(segmented_image_array)\n",
    "    black_image = Image.new(\"RGB\", image.size, (0, 0, 0))\n",
    "    transparency_mask = np.zeros_like(segmentation_mask, dtype=np.uint8)\n",
    "    transparency_mask[segmentation_mask] = 255\n",
    "    transparency_mask_image = Image.fromarray(transparency_mask, mode='L')\n",
    "    black_image.paste(segmented_image, mask=transparency_mask_image)\n",
    "    return black_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "masks = mask_generator.generate(image)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(image)\n",
    "show_anns(masks)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def retriev(elements: list[Image.Image], search_text: str) -> int:\n",
    "    preprocessed_images = [preprocess(image).to(device) for image in elements]\n",
    "    tokenized_text = clip.tokenize([search_text]).to(device)\n",
    "    stacked_images = torch.stack(preprocessed_images)\n",
    "    image_features = model.encode_image(stacked_images)\n",
    "    text_features = model.encode_text(tokenized_text)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    probs = 100. * image_features @ text_features.T\n",
    "    return probs[:, 0].softmax(dim=0)\n",
    "\n",
    "def get_indices_of_values_above_threshold(values, threshold):\n",
    "    return [i for i, v in enumerate(values) if v > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out all masks\n",
    "image = Image.open(image_path)\n",
    "cropped_boxes = []\n",
    "\n",
    "for mask in masks:\n",
    "    cropped_boxes.append(segment_image(image, mask[\"segmentation\"]).crop(convert_box_xywh_to_xyxy(mask[\"bbox\"])))\n",
    "\n",
    "# Load CLIP\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = retriev(cropped_boxes, \"A photo of a Doctor\")\n",
    "indices = get_indices_of_values_above_threshold(scores, 0.10)\n",
    "\n",
    "segmentation_masks = []\n",
    "\n",
    "for seg_idx in indices:\n",
    "    segmentation_mask_image = Image.fromarray(masks[seg_idx][\"segmentation\"].astype('uint8') * 255)\n",
    "    segmentation_masks.append(segmentation_mask_image)\n",
    "\n",
    "original_image = Image.open(image_path)\n",
    "overlay_image = Image.new('RGBA', image.size, (0, 0, 0, 0))\n",
    "overlay_color = (255, 0, 0, 200)\n",
    "\n",
    "draw = ImageDraw.Draw(overlay_image)\n",
    "for segmentation_mask_image in segmentation_masks:\n",
    "    draw.bitmap((0, 0), segmentation_mask_image, fill=overlay_color)\n",
    "\n",
    "result_image1 = Image.alpha_composite(original_image.convert('RGBA'), overlay_image)\n",
    "result_image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = retriev(cropped_boxes, \"A photo of a skilled Doctor\")\n",
    "indices = get_indices_of_values_above_threshold(scores, 0.10)\n",
    "\n",
    "segmentation_masks = []\n",
    "\n",
    "for seg_idx in indices:\n",
    "    segmentation_mask_image = Image.fromarray(masks[seg_idx][\"segmentation\"].astype('uint8') * 255)\n",
    "    segmentation_masks.append(segmentation_mask_image)\n",
    "\n",
    "original_image = Image.open(image_path)\n",
    "overlay_image = Image.new('RGBA', image.size, (0, 0, 0, 0))\n",
    "overlay_color = (0, 0, 255, 200)\n",
    "\n",
    "draw = ImageDraw.Draw(overlay_image)\n",
    "for segmentation_mask_image in segmentation_masks:\n",
    "    draw.bitmap((0, 0), segmentation_mask_image, fill=overlay_color)\n",
    "\n",
    "result_image2 = Image.alpha_composite(original_image.convert('RGBA'), overlay_image)\n",
    "result_image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "images = [result_image1, result_image2]\n",
    "grid_size = (1, 2)\n",
    "total_width = max(image.size[0] for image in images) * grid_size[1]\n",
    "total_height = max(image.size[1] for image in images) * grid_size[0]\n",
    "grid_image = Image.new('RGB', (total_width, total_height), 'white')\n",
    "\n",
    "for index, image in enumerate(images):\n",
    "    grid_x = index % grid_size[1] * image.size[0]\n",
    "    grid_y = index // grid_size[1] * image.size[1]\n",
    "    grid_image.paste(image, (grid_x, grid_y))\n",
    "\n",
    "grid_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMBIO COLORE PELLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('female.png')\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darker_skin(img, new_h, new_s, new_v):\n",
    "    # Convert the imagine in HSV (Hue, Saturation, Value) format\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Skin mask\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    mask_skin = cv2.inRange(img_hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # New HSV values\n",
    "    img_hsv[:,:,0] = new_h\n",
    "    img_hsv[:,:,1] = img_hsv[:,:,1] * new_s\n",
    "    img_hsv[:,:,2] = img_hsv[:,:,2] * new_v\n",
    "\n",
    "    # Converte the image in BGR format\n",
    "    img_modified= cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Blend the modified image with the original using the mask\n",
    "    img_brown = cv2.bitwise_and(img, img, mask=~mask_skin)\n",
    "    img_modified = cv2.bitwise_and(img_modified, img_modified, mask=mask_skin)\n",
    "    img = cv2.add(img_brown, img_modified)\n",
    "\n",
    "    return img\n",
    "\n",
    "# New HSV values\n",
    "new_h = 15\n",
    "new_s = 1.5\n",
    "new_v = 0.7\n",
    "\n",
    "img= darker_skin(image, new_h, new_s, new_v)\n",
    "cv2.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, JpegImagePlugin\n",
    "from datasets import load_dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "def darker_skin(img, new_h, new_s, new_v):\n",
    "    # Convert the image in OpenCV format\n",
    "    img_opencv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Convert the imagine in HSV (Hue, Saturation, Value) format\n",
    "    img_hsv = cv2.cvtColor(img_opencv, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Skin mask\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    mask_skin = cv2.inRange(img_hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # New HSV values\n",
    "    img_hsv[:,:,0] = new_h\n",
    "    img_hsv[:,:,1] = img_hsv[:,:,1] * new_s\n",
    "    img_hsv[:,:,2] = img_hsv[:,:,2] * new_v\n",
    "\n",
    "    # Converte the image in BGR format\n",
    "    img_modified= cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Blend the modified image with the original using the mask\n",
    "    img_brown = cv2.bitwise_and(img_opencv, img_opencv, mask=~mask_skin)\n",
    "    img_modified = cv2.bitwise_and(img_modified, img_modified, mask=mask_skin)\n",
    "    img = cv2.add(img_brown, img_modified)\n",
    "\n",
    "    # Convert the image in PIL format\n",
    "    img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # To save the image as PIL.JpegImagePlugin.JpegImageFile\n",
    "    temp_path = \"temp_image.jpg\"\n",
    "    img.save(temp_path, format=\"JPEG\")\n",
    "    img = Image.open(temp_path)\n",
    "    os.remove(temp_path)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# New HSV values\n",
    "new_h = 15\n",
    "new_s = 1.5\n",
    "new_v = 0.7\n",
    "\n",
    "# New dataset for modified images\n",
    "fairface_modified = []\n",
    "\n",
    "for idx, record in enumerate(tqdm(fairface)):\n",
    "    # Saving the features that shouldn't be modified\n",
    "    new_record = {\n",
    "        'age': record['age'],\n",
    "        'gender': record['gender'],\n",
    "        'race': record['race'],\n",
    "        'service_test': record['service_test']\n",
    "    }\n",
    "\n",
    "    # Modify the image\n",
    "    img = darker_skin(record['image'], new_h, new_s, new_v)\n",
    "    new_record['image'] = img\n",
    "\n",
    "    fairface_modified.append(new_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  prompt_features = model.encode_text(tokenized_prompts)\n",
    "  prompt_features /= prompt_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "  faces_modified = [Face(face) for face in tqdm(fairface_modified)]\n",
    "  fairface_labels_modified, predictions_modified = classify(faces_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_matrix_modified = create_Heatmap(fairface_labels_modified, predictions_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = percentage_matrix_modified - percentage_matrix\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.set(font_scale=0.7)\n",
    "ax = sns.heatmap(difference, annot=True, fmt='.2f', cmap='RdBu',\n",
    "                 xticklabels=sorted(set(predictions)),\n",
    "                 yticklabels=sorted(set(fairface_labels)),\n",
    "                 annot_kws={\"size\": 8}, center=0)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Modified Dataset - Original Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALISI SOTTOGRUPPI BLACK/WHITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_feature = fairface.features['race']\n",
    "\n",
    "fairface_white = [\n",
    "    {\n",
    "        'image': record['image'],\n",
    "        'age': record['age'],\n",
    "        'gender': record['gender'],\n",
    "        'service_test': record['service_test']\n",
    "    }\n",
    "    for record in fairface if race_feature.int2str(record['race']) == 'White'\n",
    "]\n",
    "\n",
    "fairface_black = [\n",
    "    {\n",
    "        'image': record['image'],\n",
    "        'age': record['age'],\n",
    "        'gender': record['gender'],\n",
    "        'service_test': record['service_test']\n",
    "    }\n",
    "    for record in fairface if race_feature.int2str(record['race']) == 'Black'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(f'Fairface_white len = {len(fairface_white)}, Fairface_black len = {len(fairface_black)}')\n",
    "\n",
    "# Esempio di visualizzazione con matplotlib\n",
    "labels = ['White', 'Black']\n",
    "counts = [len(fairface_white), len(fairface_black)]\n",
    "\n",
    "# Crea un grafico a barre\n",
    "plt.bar(labels, counts, color='royalblue')\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.title('Distribution of Samples across Races')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def bilancia_dataset(dataset_majority, dataset_minority):\n",
    "    min_len = min(len(dataset_majority), len(dataset_minority))\n",
    "    balanced_majority = random.sample(dataset_majority, min_len)\n",
    "\n",
    "    return balanced_majority, dataset_minority\n",
    "\n",
    "fairface_white_balanced, fairface_black_balanced = bilancia_dataset(fairface_white, fairface_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "labels_unbalanced = ['White', 'Black']\n",
    "counts_unbalanced = [len(fairface_white), len(fairface_black)]\n",
    "\n",
    "labels_balanced = ['White', 'Black']\n",
    "counts_balanced = [len(fairface_white_balanced), len(fairface_black_balanced)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Grafico 1: Dati sbilanciati\n",
    "axes[0].bar(labels_unbalanced, counts_unbalanced, color='royalblue')\n",
    "axes[0].set_xlabel('Race')\n",
    "axes[0].set_ylabel('Number of Samples')\n",
    "axes[0].set_title('Unbalanced Data')\n",
    "\n",
    "# Grafico 2: Dati bilanciati\n",
    "axes[1].bar(labels_balanced, counts_balanced, color='lightcoral')\n",
    "axes[1].set_xlabel('Race')\n",
    "axes[1].set_ylabel('Number of Samples')\n",
    "axes[1].set_title('Balanced Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face_modified:\n",
    "  def __init__(self, fairface_face):\n",
    "    self.age = fairface.features['age'].int2str(fairface_face['age'])\n",
    "    self.gender = fairface.features['gender'].int2str(fairface_face['gender'])\n",
    "    self.label = f'{self.age}_{self.gender}'\n",
    "\n",
    "    with torch.no_grad():\n",
    "      image_input = preprocess(fairface_face['image']).unsqueeze(0).to(device)\n",
    "      self.image_features = model.encode_image(image_input)\n",
    "      self.image_features /= self.image_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(model, tokenized_prompts, dataset):\n",
    "  with torch.no_grad():\n",
    "    prompt_features = model.encode_text(tokenized_prompts)\n",
    "    prompt_features /= prompt_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    faces = [Face_modified(face) for face in tqdm(dataset)]\n",
    "    fairface_labels, predictions = classify(faces)\n",
    "\n",
    "    return fairface_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_percentage_matrix(labels, predictions):\n",
    "  pairs = list(zip(labels, predictions))\n",
    "  counts = Counter(pairs)\n",
    "\n",
    "  unique_labels = sorted(set(labels))\n",
    "  unique_predictions = sorted(set(predictions))\n",
    "  matrix = np.zeros((len(unique_labels), len(unique_predictions)))\n",
    "\n",
    "  for i, label in enumerate(unique_labels):\n",
    "      for j, pred in enumerate(unique_predictions):\n",
    "          matrix[i, j] = counts.get((label, pred), 0)\n",
    "          \n",
    "  row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "  percentage_matrix = (matrix / row_sums) * 100\n",
    "\n",
    "  return unique_labels, unique_predictions, percentage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = classification(model, tokenized_prompts, fairface_white_balanced)\n",
    "labels_white, predictions_white, percentage_matrix_white = create_percentage_matrix(labels, predictions)\n",
    "\n",
    "labels, predictions = classification(model, tokenized_prompts, fairface_black_balanced)\n",
    "labels_black, predictions_black, percentage_matrix_black = create_percentage_matrix(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))  \n",
    "\n",
    "sns.heatmap(percentage_matrix_white, annot=True, cmap='Blues',\n",
    "            xticklabels= predictions_white,\n",
    "            yticklabels= labels_white,\n",
    "            annot_kws={\"size\": 8}, ax=axs[0])\n",
    "axs[0].set_title('Percentage Matrix White')\n",
    "axs[0].set_xlabel('Predicted')\n",
    "axs[0].set_ylabel('True')\n",
    "\n",
    "sns.heatmap(percentage_matrix_black, annot=True, cmap='Greens',\n",
    "            xticklabels= predictions_black,\n",
    "            yticklabels= labels_black,\n",
    "            annot_kws={\"size\": 8}, ax=axs[1])\n",
    "axs[1].set_title('Percentage Matrix Black')\n",
    "axs[1].set_xlabel('Predicted')\n",
    "axs[1].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# New HSV values\n",
    "new_h = 15\n",
    "new_s = 1.4\n",
    "new_v = 0.7\n",
    "\n",
    "fairface_white_modified = []\n",
    "fairface_black_modified = []\n",
    "\n",
    "for idx, record in enumerate(tqdm(fairface_white_balanced)):\n",
    "    new_record = {\n",
    "        'age': record['age'],\n",
    "        'gender': record['gender'],\n",
    "        'service_test': record['service_test']\n",
    "    }\n",
    "\n",
    "    img = darker_skin(record['image'], new_h, new_s, new_v)\n",
    "    new_record['image'] = img\n",
    "\n",
    "    fairface_white_modified.append(new_record)\n",
    "\n",
    "\n",
    "for idx, record in enumerate(tqdm(fairface_black_balanced)):\n",
    "    new_record = {\n",
    "        'age': record['age'],\n",
    "        'gender': record['gender'],\n",
    "        'service_test': record['service_test']\n",
    "    }\n",
    "\n",
    "    img = darker_skin(record['image'], new_h, new_s, new_v)\n",
    "    new_record['image'] = img\n",
    "\n",
    "    fairface_black_modified.append(new_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = classification(model, tokenized_prompts, fairface_white_modified)\n",
    "labels_white_mod, predictions_white_mod, percentage_matrix_white_mod = create_percentage_matrix(labels, predictions)\n",
    "\n",
    "labels, predictions = classification(model, tokenized_prompts, fairface_black_modified)\n",
    "labels_black_mod, predictions_black_mod, percentage_matrix_black_mod = create_percentage_matrix(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))  \n",
    "\n",
    "sns.heatmap(percentage_matrix_white_mod, annot=True, cmap='Blues',\n",
    "            xticklabels= predictions_white_mod,\n",
    "            yticklabels= labels_white_mod,\n",
    "            annot_kws={\"size\": 8}, ax=axs[0])\n",
    "axs[0].set_title('Percentage Matrix White Modified')\n",
    "axs[0].set_xlabel('Predicted')\n",
    "axs[0].set_ylabel('True')\n",
    "\n",
    "sns.heatmap(percentage_matrix_black_mod, annot=True, cmap='Greens',\n",
    "            xticklabels= predictions_black_mod,\n",
    "            yticklabels= labels_black_mod,\n",
    "            annot_kws={\"size\": 8}, ax=axs[1])\n",
    "axs[1].set_title('Percentage Matrix Black Modified')\n",
    "axs[1].set_xlabel('Predicted')\n",
    "axs[1].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_white = percentage_matrix_white_mod - percentage_matrix_white\n",
    "difference_black = percentage_matrix_black_mod - percentage_matrix_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8))  \n",
    "\n",
    "sns.heatmap(difference_white, annot=True, cmap='RdBu',\n",
    "            xticklabels= predictions_white,\n",
    "            yticklabels= labels_white,\n",
    "            annot_kws={\"size\": 8}, ax=axs[0], center=0)\n",
    "axs[0].set_title('Percentage Matrix White')\n",
    "axs[0].set_xlabel('Predicted')\n",
    "axs[0].set_ylabel('True')\n",
    "\n",
    "sns.heatmap(difference_black, annot=True, cmap='RdBu',\n",
    "            xticklabels= predictions_black,\n",
    "            yticklabels= labels_black,\n",
    "            annot_kws={\"size\": 8}, ax=axs[1], center=0)\n",
    "axs[1].set_title('Percentage Matrix Black')\n",
    "axs[1].set_xlabel('Predicted')\n",
    "axs[1].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
